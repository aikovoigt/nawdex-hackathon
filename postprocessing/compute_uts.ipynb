{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate upper-tropospheric stability\n",
    "\n",
    "UTS defined as difference of potential temperature between the dynamic tropopause (defined as the 2PVU level) and 3 km below the 2PVU level similar to Li et al, JGR, 2014, doi: 10.1002/2013JD020669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import dask\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "#for time and memory impression:\n",
    "import psutil\n",
    "import time as tm\n",
    "import datetime \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants declaration, values taken from ICON source code\n",
    "Cp = 1004.64 #J kg K-1\n",
    "Ra = 287.04  #J kg-1 K-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dictionary will all simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/pf/b/b380459/nawdex-hackathon/')\n",
    "import dict_nawdexsims\n",
    "simdict   = dict_nawdexsims.simdictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_memory(msg=None):\n",
    "    process = psutil.Process()\n",
    "    mem = np.round(process.memory_info().rss/(1024*1024))\n",
    "    return mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(expid):\n",
    "    \n",
    "    # load data\n",
    "    path  = '/scratch/b/b380459/icon_4_hackathon/'\n",
    "    fname = path+'/'+expid+'/'+expid+'_2016*_fg_DOM01_ML_*.nc'\n",
    "    ds_fg = ( xr.open_mfdataset(fname, combine='by_coords',parallel=True, \n",
    "                                engine='h5netcdf', chunks={'time': 1})\n",
    "                                [['temp', 'pres', 'z_ifc']].rename({'ncells_2': 'ncells', 'height_3': 'height_ifc'}) )\n",
    "    fname = path+'/'+expid+'/'+expid+'_2016*_pv_DOM01_ML_*.nc'\n",
    "    ds_pv = ( xr.open_mfdataset(fname, combine='by_coords', parallel=True, \n",
    "                                engine='h5netcdf', chunks={'time': 1})\n",
    "                                [['pv']] )\n",
    "    \n",
    "    # merge datasets\n",
    "    ds = xr.merge([ds_pv, ds_fg])\n",
    "    del(ds_pv, ds_fg)\n",
    "    \n",
    "    # compute height at full levels\n",
    "    # !!! ATTENTION !!!\n",
    "    ds['dz'] = -1*ds['z_ifc'].diff(dim='height_ifc', n=1, label='lower').rename({'height_ifc': 'height'})\n",
    "    ds['z']  = ( ds['z_ifc'].isel(height_ifc=slice(0,75)).rename({'height_ifc': 'height'}) \n",
    "                 - 0.5*ds['dz'].isel(height=slice(0,75)) )\n",
    "    ds = ds.drop(['z_ifc'])\n",
    "    \n",
    "    # change units to PVU\n",
    "    ds['pv'] = ds['pv'] * 1000000\n",
    "    ds.pv.attrs['units']='PVU'\n",
    "  \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_timeloop(expid,tstep):\n",
    "      \n",
    "    # load data\n",
    "    path  = '/scratch/b/b380459/icon_4_hackathon/'\n",
    "    fname = path+'/'+expid+'/'+expid+'_2016*_fg_DOM01_ML_'+str(tstep).zfill(4)+'.nc'\n",
    "    #print(fname)\n",
    "    ds_fg = ( xr.open_mfdataset(fname, combine='by_coords',parallel=True, \n",
    "                                engine='h5netcdf', chunks={'ncells_2': 1e6})\n",
    "                                [['temp', 'pres', 'z_ifc']].rename({'ncells_2': 'ncells', 'height_3': 'height_ifc'}) )\n",
    "    fname = path+'/'+expid+'/'+expid+'_2016*_pv_DOM01_ML_'+str(tstep).zfill(4)+'.nc'\n",
    "    #print(fname)\n",
    "    ds_pv = ( xr.open_mfdataset(fname, combine='by_coords', parallel=True, \n",
    "                                engine='h5netcdf', chunks={'ncells': 1e6})\n",
    "                                [['pv']] )\n",
    "    \n",
    "    # merge datasets\n",
    "    ds = xr.merge([ds_pv, ds_fg])\n",
    "    del(ds_pv, ds_fg)\n",
    "    \n",
    "    # compute height at full levels\n",
    "    # !!! ATTENTION !!!\n",
    "    ds['dz'] = -1*ds['z_ifc'].diff(dim='height_ifc', n=1, label='lower').rename({'height_ifc': 'height'})\n",
    "    ds['z']  = ( ds['z_ifc'].isel(height_ifc=slice(0,75)).rename({'height_ifc': 'height'}) \n",
    "                 - 0.5*ds['dz'].isel(height=slice(0,75)) )\n",
    "    ds = ds.drop(['z_ifc'])\n",
    "    \n",
    "    # change units to PVU\n",
    "    ds['pv'] = ds['pv'] * 1000000\n",
    "    ds.pv.attrs['units']='PVU'\n",
    "  \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uts(heightlim_top, heightlim_bot):\n",
    "    \n",
    "    #index, height and theta at 2PVU level\n",
    "    #NOTE: a (subjective) height limit is set, in order to avoid 2PVU features in the troposphere. \n",
    "    ds['ind_tropheight'] = (( abs(ds.pv.isel(height=slice(heightlim_top,heightlim_bot)) - 2) ).argmin(dim='height') + heightlim_top )\n",
    "    ds['ind_tropheight'] = ds['ind_tropheight'].where(ds['ind_tropheight'] != heightlim_top, 0)\n",
    "    ds['tropheight'] = ds['z'].where(ds.height == ds['ind_tropheight'],-999).max(dim='height')\n",
    "    ds['theta_trop'] = ds['theta'].where(ds.height == ds['ind_tropheight'],-999).max(dim='height')\n",
    "\n",
    "    #index, height and theta at the level 3km below 2PVU level\n",
    "    ds['ind_lowheight'] = abs(ds['z'] - (ds['tropheight']-3000)).argmin(dim='height')\n",
    "    ds['lowheight'] = ds['z'].where(ds.height == ds['ind_lowheight'],-999).max(dim='height')\n",
    "    ds['theta_low'] = ds['theta'].where(ds.height == ds['ind_lowheight'],-999).max(dim='height')   \n",
    "\n",
    "    # upper tropospheric stability [K/km]\n",
    "    ds['uts'] = (ds['theta_trop'] - ds['theta_low']) / ( (ds['tropheight'] - ds['lowheight']) /1000 )\n",
    "    ds['uts'] = ds['uts'].where(ds['uts'] < 100, -10)\n",
    "    \n",
    "    return ds['uts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for sim in list(simdict.keys()):\n",
    "    mem_before = def_memory()\n",
    "    time_start = tm.time()\n",
    "    # zarr store\n",
    "    zarr_store = '/scratch/b/b380459/icon_4_hackathon/upper_tropo_stability/uts_'+sim+'.zarr'\n",
    "    # remove any zarr_store with same name that might have been created previously\n",
    "    shutil.rmtree(zarr_store, ignore_errors=True) \n",
    "    \n",
    "    if sim[0:13] == 'nawdexnwp-2km':\n",
    "        print('Working on:', sim)\n",
    "        print('      Starting at: ', datetime.datetime.now().time())\n",
    "        # create sorted list of available timesteps\n",
    "        tstep_list = []\n",
    "        for i in Path('/scratch/b/b380459/icon_4_hackathon/'+sim).rglob(sim+'_2016*_fg_DOM01_ML_*.nc'):\n",
    "            tstep_list.append(str(i).split('/')[-1].split('_')[5].split('.')[0])\n",
    "        tstep_list.sort(key=int)\n",
    "        # loop over all available timesteps, provided the timestep list is not empty\n",
    "        if tstep_list:\n",
    "            for tstep in tstep_list:\n",
    "                ds = load_data_timeloop(sim, tstep)\n",
    "                ds['theta'] = ds['temp'] * (100000./ds['pres'])**(Ra/Cp)\n",
    "                ds['UTS'] = calc_uts(15,50)\n",
    "                ds = ds.drop(['temp','pres','theta','pv','dz','z'])\n",
    "                ds = ds.drop(['ind_tropheight','tropheight','theta_trop','ind_lowheight','lowheight','theta_low'])\n",
    "                ds.attrs['units'] = 'Kelvin km-1'\n",
    "                ds.attrs['description'] = 'upper tropospheric stability'\n",
    "                ds.attrs['simulation'] = sim\n",
    "                \n",
    "                # if this is the first timestep, then create new zarr store, otherwise append to existing zarr store\n",
    "                if Path(zarr_store).exists():\n",
    "                    ds[['UTS']].to_zarr(zarr_store, append_dim='time')\n",
    "                else:\n",
    "                    ds[['UTS']].to_zarr(zarr_store)\n",
    "    \n",
    "    else:\n",
    "        print('Working on:', sim)\n",
    "        ds = load_data(sim)\n",
    "        ds['theta'] = ds['temp'] * (100000./ds['pres'])**(Ra/Cp)\n",
    "        ds['UTS'] = calc_uts(15,50)\n",
    "        ds = ds.drop(['temp','pres','theta','pv','dz','z'])\n",
    "        ds = ds.drop(['ind_tropheight','tropheight','theta_trop','ind_lowheight','lowheight','theta_low'])\n",
    "        ds.attrs['units'] = 'Kelvin km-1'\n",
    "        ds.attrs['description'] = 'upper tropospheric stability'\n",
    "        ds.attrs['simulation'] = sim\n",
    "        # store to zarr store\n",
    "        ds[['UTS']].to_zarr(zarr_store)\n",
    "    \n",
    "    mem_after = def_memory()\n",
    "    time_elapsed = (tm.time() - time_start) /60.\n",
    "    print('      Memory before and after loading data: ', mem_before,'MB --> ', mem_after,'MB') \n",
    "    print('      Time elapsed (min): ', time_elapsed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nawdex-hackathon",
   "language": "python",
   "name": "nawdex-hackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
