{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch analysis for sampling any 2d or 3d field as a function of cloud controlling factors\n",
    "\n",
    "Note: we use the numpy implementation of digitize, which has proven easy to use and sufficiently fast.\n",
    "\n",
    "Aiko Voigt, KIT, 15 Oct 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import zarr\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pf/b/b380459/conda-envs/Nawdex-Hackathon/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 39057 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "dask.config.set({\"array.slicing.split_large_chunks\": True})\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:41506</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:39057/status' target='_blank'>http://127.0.0.1:39057/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>48</li>\n",
       "  <li><b>Memory: </b>134.22 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:41506' processes=8 threads=48, memory=134.22 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/pf/b/b380459/nawdex-hackathon/')\n",
    "\n",
    "import dict_nawdexsims\n",
    "simdict = dict_nawdexsims.simdictionary()\n",
    "\n",
    "import nawdexutils as nawut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ancillary functions for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_griddata(gridres):\n",
    "    path  = '/scratch/b/b380459/icon_4_hackathon/'\n",
    "    dict_gridres={'80km': 'R80000m', '40km': 'R40000m', '20km': 'R20000m',\n",
    "                  '10km': 'R10000m', '5km': 'R5000m', '2km': 'R2500m'}\n",
    "    fname = path+'/grids/icon-grid_nawdex_78w40e23n80n_'+dict_gridres[gridres]+'.nc'\n",
    "    return xr.open_dataset(fname)['cell_area'].rename({'cell': 'ncells'}) \n",
    "\n",
    "def load_openoceanmask(expid):\n",
    "    path  = '/scratch/b/b380459/icon_4_hackathon/'\n",
    "    fname = path+'/openocean_masks/'+expid+'_openoceanmask.nc'\n",
    "    return xr.open_dataset(fname)['mask_openocean']  \n",
    "\n",
    "def load_ccf(expid, ccf):\n",
    "    path  = '/scratch/b/b380459/icon_4_hackathon/'\n",
    "    dict_stream = {'omega': 'rh_omega_DOM01_PL', 't_g': '2d_30min_DOM01_ML'}\n",
    "    fname = path+'/'+expid+'/'+expid+'_2016*_'+dict_stream[ccf]+'_0*.nc'\n",
    "    ds = ( xr.open_mfdataset(fname,combine='by_coords',parallel=True, \n",
    "                             engine='h5netcdf', chunks={'time': 1})\n",
    "           [ccf].resample(time=\"1H\").nearest(tolerance=\"5M\") )\n",
    "    if ccf == 'omega':\n",
    "        ds = ds.sel(lev=500e2)\n",
    "    return ds\n",
    "\n",
    "def load_var(expid, var):\n",
    "    path  = '/scratch/b/b380459/icon_4_hackathon/'\n",
    "    dict_stream = {'clct': '2d_30min', 'clc': '3dcloud'}\n",
    "    fname = path+'/'+expid+'/'+expid+'_2016*_'+dict_stream[var]+'_DOM01_ML_0*.nc'\n",
    "    return ( xr.open_mfdataset(fname,\n",
    "                               combine='by_coords',parallel=True, \n",
    "                               engine='h5netcdf', chunks={'time': 1})\n",
    "             [var].resample(time=\"1H\").nearest(tolerance=\"5M\") )\n",
    "\n",
    "def load_var_ddt_temp_rad_fromflux(expid, var):\n",
    "    path  = '/scratch/b/b380459/icon_4_hackathon/'\n",
    "    # open previously calculated radiative heating rates from zarr store\n",
    "    zarr_store = '/scratch/b/b380459/icon_4_hackathon/'+expid+'/'+expid+'_ddttemp_rad-from-fluxes_DOM01_ML.zarr'\n",
    "    return ( xr.open_zarr(zarr_store)\n",
    "             [var].resample(time=\"1H\").nearest(tolerance=\"5M\") )\n",
    "\n",
    "# Load cloud controlling factor, which is a 2d field (time x ncells)\n",
    "def prepare_ccf_dataset(expid, resolution, ccf):\n",
    "    \n",
    "    # open ocean mask\n",
    "    da_oom = load_openoceanmask(expid)\n",
    "    index  = np.where(da_oom==1)[0]\n",
    "    \n",
    "    # load data and only keep cells over open ocean\n",
    "    ds_grid = load_griddata(resolution).isel(ncells=index)\n",
    "    ds_ccf  = load_ccf(expid, ccf).isel(ncells=index)\n",
    "    \n",
    "    return xr.merge([ds_grid, ds_ccf])\n",
    "\n",
    "# Load variable that will be sampled on cloud controlling factor, this\n",
    "# can be a 2d field (time x ncells) or a 3d field (time x height x ncells), \n",
    "# and it can also be the radiative heating rates provided in zarr stores\n",
    "def prepare_var_dataset(expid, resolution, var):\n",
    "    # open ocean mask\n",
    "    da_oom = load_openoceanmask(expid)\n",
    "    index  = np.where(da_oom==1)[0]\n",
    "    \n",
    "    # load data and only keep cells over open ocean\n",
    "    ds_grid = load_griddata(resolution).isel(ncells=index)\n",
    "    # special treament for diagnosed rad heating rates stored in zarr stores\n",
    "    if var in ['ddt_temp_radlw_fromflux', 'ddt_temp_radlwclr_fromflux',\n",
    "               'ddt_temp_radsw_fromflux', 'ddt_temp_radswclr_fromflux']:\n",
    "        ds_var  = load_var_ddt_temp_rad_fromflux(expid, var).isel(ncells=index)\n",
    "    else:\n",
    "        ds_var  = load_var(expid, var).isel(ncells=index)\n",
    "    \n",
    "    \n",
    "    return xr.merge([ds_grid, ds_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ancillary functions for indexing ccf data and for sampling variable on ccf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to index grid cells according to which bin in the ccf they belong to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ccf_binindexing(ds_in, nbins, binrange):\n",
    "    # input: dataset ds_in, assumed to contain the cloud controlling factor (ccf)\n",
    "    # as well as the surface area of the grid cells (cell_area)\n",
    "    # output: for each cell and time step, the function return the binning index\n",
    "    # of the cloud controlling factor\n",
    "    \n",
    "    # define surface area weights, which we add to output dataset for later use\n",
    "    weights = np.broadcast_to(ds_in['cell_area'], ds_in['ccf'].shape)\n",
    "    # define binning edges based on \n",
    "    bins_edges = np.linspace(binrange[0], binrange[1], nbins+1)\n",
    "    # calculate centre of bins from the edges of the bins\n",
    "    bins = bins_edges[1:] - 0.5*np.abs(bins_edges[1]-bins_edges[0])\n",
    "    # for each entry of omega, ccf_indices gives the bin index it belongs to\n",
    "    ccf_indices  = np.digitize(ds_in['ccf'], bins)\n",
    "    \n",
    "    # make an output dataset that contains ccf_indices, weights, bins and bins_edges\n",
    "    ds_out = ( xr.Dataset(\n",
    "               {'ccf_indices': (['time','ncells'], ccf_indices),\n",
    "                'weights': (['time','ncells'], weights),},\n",
    "                coords={'time': (['time'], ds_in.time),\n",
    "                        'bins': (['bins'], bins),\n",
    "                        'bins_edges': (['bins_edges'], bins_edges),\n",
    "                        'clon': (['ncells'], ds_in.clon),\n",
    "                        'clat': (['ncells'], ds_in.clat)},\n",
    "    ) )\n",
    "    ds_out['time'].attrs = ds_in['time'].attrs\n",
    "    ds_out['bins'].attrs['units'] = ds_in['ccf'].attrs['units']\n",
    "    ds_out['bins_edges'].attrs['units'] = ds_in['ccf'].attrs['units']\n",
    "    \n",
    "    # return dataset\n",
    "    return ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to sampled variable based on cloud controlling factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_var_ccfsampled_2dvar(ds_ccfindex, ds_var, varname):\n",
    "    # resample data on ccf bins using numpy for variables with input dimension time x ncells\n",
    "    \n",
    "    # number of bins\n",
    "    nbins = ds_ccfindex['bins'].size\n",
    "    var_sampled = np.zeros(nbins)\n",
    "    \n",
    "    # convert to numpy arrays\n",
    "    indices = ds_ccfindex['ccf_indices'].values\n",
    "    weights = ds_ccfindex['weights'].values\n",
    "    var_x_weights =  ds_var[varname].values * weights\n",
    "    \n",
    "    for n in range(0, nbins):\n",
    "        var_sampled[n] = ( np.nansum(var_x_weights[indices==n]) \n",
    "                              / np.nansum(weights[indices==n]) )\n",
    "        \n",
    "    return var_sampled\n",
    "\n",
    "def make_var_ccfsampled_3dvar(ds_ccfindex, ds_var, varname):\n",
    "    # resample data on ccf bins using numpy for variables with input dimension time x height x ncells\n",
    "    \n",
    "    # number of bins\n",
    "    nbins = ds_ccfindex['bins'].size\n",
    "    var_sampled = np.zeros((nbins, ds_var.height.size))\n",
    "    \n",
    "    # convert to numpy arrays\n",
    "    indices = ds_ccfindex['ccf_indices'].values\n",
    "    # var needs to be in shape time x ncells x height\n",
    "    var = np.transpose(ds_var[varname].values, axes=[0,2,1])\n",
    "    weights = ds_ccfindex['weights'].values\n",
    "    var_x_weights =  var * np.expand_dims(weights, axis=2)\n",
    "        \n",
    "    for n in range(0, nbins):\n",
    "        var_sampled[n] = ( np.nansum(var_x_weights[indices==n], axis=0) \n",
    "                              / np.nansum(weights[indices==n]) )\n",
    "        \n",
    "    return var_sampled\n",
    "\n",
    "def make_var_ccfsampled(ds_ccfindex, ds_var, varname):\n",
    "    if ds_var[varname].ndim == 2:    # 2d data\n",
    "        var_sampled = make_var_ccfsampled_2dvar(ds_ccfindex, ds_var, varname)\n",
    "    elif ds_var[varname].ndim == 3:  # 3d data\n",
    "        var_sampled = make_var_ccfsampled_3dvar(ds_ccfindex, ds_var, varname)  \n",
    "    return var_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch analysis over simulations, different cloud controlling factors and different variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define cloud controlling factor and to-be-sampled variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First do the indexing of the grid cells according to the cloud controlling factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on  nawdexnwp-10km-mis-0011 with resolution 10km\n",
      "Working on  nawdexnwp-10km-mis-0012 with resolution 10km\n"
     ]
    }
   ],
   "source": [
    "ccf='t_g'\n",
    "\n",
    "dict_binning={'omega':{'nbins':50, 'binrange': [-1.0, 1.0]},\n",
    "              't_g'  :{'nbins':74, 'binrange': [273.0, 310.0]}}\n",
    "\n",
    "for sim in list(simdict.keys()): \n",
    "    gridres = (simdict[sim])['res']\n",
    "    if gridres != '5km' and gridres != '2km':\n",
    "        print('Working on ', sim, 'with resolution', gridres)\n",
    "        ds_ccf = prepare_ccf_dataset(sim, gridres, ccf)\n",
    "        ds_ccf = nawut.drop_first_day(ds_ccf)\n",
    "        ds_ccfindex = make_ccf_binindexing(ds_ccf[[ccf,'cell_area']].rename({ccf:'ccf'}), \n",
    "                                           nbins=dict_binning[ccf]['nbins'],\n",
    "                                           binrange=dict_binning[ccf]['binrange'])\n",
    "        ds_ccfindex.attrs['ccf'] = ccf\n",
    "        ds_ccfindex.attrs['simulation'] = sim\n",
    "        # store to zarr store\n",
    "        zarr_store = '/scratch/b/b380459/icon_4_hackathon/ccf/'+sim+'_ccf_indexing_'+ccf+'.zarr'\n",
    "        # remove any zarr_store with same name that might have been created previously\n",
    "        shutil.rmtree(zarr_store, ignore_errors=True)\n",
    "        ds_ccfindex.to_zarr(zarr_store)    \n",
    "        del ds_ccfindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now sample variable on cloud conrolling factor using previously calculated grid cell indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on  nawdexnwp-10km-mis-0002 with resolution 10km\n"
     ]
    }
   ],
   "source": [
    "ccf='omega'\n",
    "#ccf='t_g'\n",
    " \n",
    "#var='ddt_temp_radlwclr_fromflux'  \n",
    "var='clc'\n",
    "\n",
    "for sim in ['nawdexnwp-10km-mis-0002']: #list(simdict.keys()): \n",
    "    gridres = (simdict[sim])['res']\n",
    "    if gridres =='10km': # and gridres != '5km' and gridres != '2km':\n",
    "        print('Working on ', sim, 'with resolution', gridres)\n",
    "        ds_var  = prepare_var_dataset(sim, gridres, var)\n",
    "        ds_var = nawut.drop_first_day(ds_var)\n",
    "        # open previously calculated ccf indexing from zarr store\n",
    "        zarr_store = '/scratch/b/b380459/icon_4_hackathon/ccf/'+sim+'_ccf_indexing_'+ccf+'.zarr'\n",
    "        ds_ccfindex = xr.open_zarr(zarr_store)\n",
    "        var_ccfsampled = make_var_ccfsampled(ds_ccfindex, ds_var, var)\n",
    "        # store to netcdf file   \n",
    "        if var_ccfsampled.ndim==1: # 2-d field\n",
    "            var_ccfsampled = xr.DataArray(var_ccfsampled, dims=['bins'], coords={'bins': ds_ccfindex.bins})\n",
    "        if var_ccfsampled.ndim==2: # 3-dfield\n",
    "            var_ccfsampled = xr.DataArray(var_ccfsampled, dims=['bins', 'height'], \n",
    "                                          coords={'bins': ds_ccfindex.bins, 'height': ds_var.height})\n",
    "        var_ccfsampled.name = var+'_ccfsampled'\n",
    "        var_ccfsampled.attrs['ccf'] = ccf\n",
    "        var_ccfsampled.attrs['description'] = var+' sampled on '+ccf+', only over open ocean'\n",
    "        var_ccfsampled.attrs['simulation'] = sim\n",
    "        var_ccfsampled.to_netcdf('/scratch/b/b380459/icon_4_hackathon/ccf/'+sim+'_'+var+'_sampled_on_'+ccf+'.nc', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up before leaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nawdex-Hackathon",
   "language": "python",
   "name": "nawdex-hackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
